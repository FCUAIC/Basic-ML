{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FCUAIC/Basic-ML/blob/main/mnist_cgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkJe9oRX0xHP"
      },
      "source": [
        "# MNIST CGAN\n",
        "\n",
        "作者: 梁定殷\n",
        "\n",
        "版權歸FCUAI所有"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAP_RwwR0xHZ"
      },
      "source": [
        "Input shape: (1, 28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QP0h2hz0xHa"
      },
      "source": [
        "## 超參數(Hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_30N5F-0xHc"
      },
      "outputs": [],
      "source": [
        "# 學習率(Learning Rate), LR越大模型越有自信, LR越小模型越沒自信\n",
        "LR = 0.0002\n",
        "# 每次學習要看過多少的Batch後才更新模型\n",
        "BATCH_SIZE = 32\n",
        "# 學習次數\n",
        "EPOCHS = 500\n",
        "\n",
        "C = 0.03\n",
        "\n",
        "用離線的MNIST = False # Pytorch的MNIST暫時不能用"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsaQUcdrzICn"
      },
      "source": [
        "## 載入需要用的Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7YoBf-40xHe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "if 用離線的MNIST:\n",
        "    from keras.datasets import mnist\n",
        "else:\n",
        "    from torchvision.datasets import MNIST\n",
        "\n",
        "\n",
        "from sklearn.model_selection import  train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm.notebook import trange, tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 固定亂數\n",
        "manualSeed = 999\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alme2j5loxfR",
        "outputId": "d49c5178-ea24-42cd-82c0-1adb13d02600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f20196c8550>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "ZzWqt8i8ZtFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHtR-7Vi0xHf"
      },
      "source": [
        "## 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "Wset3Ml-0xHf",
        "outputId": "f23efd62-4329-4a1b-864a-38a3b25791bc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-420fa854a0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNISTGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "class MNISTGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTGenerator, self).__init__()\n",
        "        self.label_embedding = nn.Embedding(10, 32)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=100 + 32, out_channels=512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=1, kernel_size=2, stride=2, padding=2, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, label):\n",
        "        embedded_label = self.label_embedding(label)\n",
        "        embedded_label = torch.reshape(embedded_label, (label.size(0), 32, 1, 1))\n",
        "        return self.net(torch.cat([noise, embedded_label], 1))\n",
        "        \n",
        "G = MNISTGenerator().cuda()\n",
        "G.apply(weights_init)\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qWsVDTAT6ZF"
      },
      "outputs": [],
      "source": [
        "class MNISTDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTDiscriminator, self).__init__()\n",
        "        self.label_embedding = nn.Sequential(\n",
        "            nn.Embedding(10, 32),\n",
        "            nn.Linear(32, 1 * 28 * 28)\n",
        "        )\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(2, 16, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(16, 32, 4, 2, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1568, 512),\n",
        "            nn.Dropout(),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, img, label):\n",
        "        label_embed = self.label_embedding(label)\n",
        "        label_reshaped = torch.reshape(label_embed, (img.size(0), 1, 28, 28))\n",
        "        inp = torch.cat([img, label_reshaped], 1)\n",
        "        cnn_oup = self.cnn(inp)\n",
        "        class_oup = self.classifier(cnn_oup)\n",
        "        return class_oup\n",
        "\n",
        "D = MNISTDiscriminator().cuda()\n",
        "D.apply(weights_init)\n",
        "print(D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxUV8qwb0xHi"
      },
      "source": [
        "## 資料集(Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx9x2weMkazV"
      },
      "outputs": [],
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    \"\"\"\n",
        "        這是我們定義的Dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, train=False, transformer=None):\n",
        "        # 從Keras載入MNIST\n",
        "        (train_feature, train_label), (test_feature, test_label) = mnist.load_data()\n",
        "        if train:\n",
        "            # 我們只要訓練的\n",
        "            self.data = np.array([list(d) for d in zip(train_feature, train_label)], dtype=object)\n",
        "            self.length = len(train_feature)\n",
        "        else:\n",
        "            # 我們只要測試的\n",
        "            self.data = np.array([list(d) for d in zip(test_feature, test_label)], dtype=object)\n",
        "            self.length = len(test_feature)\n",
        "        \n",
        "        self.transformer = transformer\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 對data做轉換\n",
        "        if self.transformer:\n",
        "            img, label = self.data[idx]\n",
        "            return self.transformer(img), torch.tensor(label, dtype=torch.long)\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJS4gVRJzZfC"
      },
      "source": [
        "## 載入資料集(Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kgkgAAz0xHk"
      },
      "outputs": [],
      "source": [
        "preprocessor = transforms.Compose([\n",
        "    transforms.ToTensor() #轉成Tensor的時候會做歸一化(Normalize)\n",
        "    ])\n",
        "\n",
        "\n",
        "if 用離線的MNIST:\n",
        "    print('使用離線的Dataset.')\n",
        "    mnist_train = MNISTDataset(train=True, transformer=preprocessor)\n",
        "    mnist_test = MNISTDataset(train=False, transformer=preprocessor)\n",
        "else:\n",
        "    print('使用Pytorch的Dataset.')\n",
        "    mnist_train = MNIST(root='mnist', download=True, transform=preprocessor, train=True)\n",
        "    mnist_test = MNIST(root='mnist', transform=preprocessor, train=False)\n",
        "\n",
        "print(f'訓練資料一共有{len(mnist_train)}筆資料\\n測試資料一共有{len(mnist_test)}筆資料')\n",
        "\n",
        "\n",
        "mnist_train = DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True) # 我們想要打散訓練資料的順序\n",
        "mnist_test = DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ADYeFqd0xHl"
      },
      "source": [
        "## 宣告損失函數&優化器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSitIE8s0xHm"
      },
      "outputs": [],
      "source": [
        "g_optim = Adam(G.parameters(), lr=LR)\n",
        "d_optim = Adam(D.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR-qq2dy0xHp"
      },
      "source": [
        "## 訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jbgexbD0xHq"
      },
      "outputs": [],
      "source": [
        "# 開始訓練\n",
        "for epoch in trange(1, EPOCHS+1, desc='Epoch', unit='次'):\n",
        "    total_d_loss = 0\n",
        "    total_g_loss = 0\n",
        "    # 給模型看很多的圖\n",
        "    for idx, (batch_x, batch_y) in tqdm(enumerate(mnist_test), desc='訓練進度', unit='batch'):\n",
        "        # 把圖跟答案放到GPU\n",
        "        x = batch_x.cuda()\n",
        "        y = batch_y.cuda()\n",
        "        # 生成噪聲\n",
        "        noise = torch.randn(x.size(0), 100, 1, 1).cuda()\n",
        "\n",
        "        d_optim.zero_grad()\n",
        "\n",
        "        # 真圖\n",
        "        d_pred_real = D(x, y).view(-1)\n",
        "        # 假圖\n",
        "        fake_data = G(noise, y)\n",
        "        d_pred_fake = D(fake_data, y).view(-1)\n",
        "        # 使用WGAN的loss算法來計算loss\n",
        "        d_loss = -torch.mean(d_pred_real) + torch.mean(d_pred_fake)\n",
        "        d_loss.backward()\n",
        "        d_optim.step()\n",
        "        total_d_loss += d_loss.item()\n",
        "\n",
        "        # 限制網路權重在-C到C之間\n",
        "        for p in D.parameters():\n",
        "            p.data.clamp_(-C, C)\n",
        "\n",
        "        # 每5次更新一次生成網路\n",
        "        if idx % 5 == 0:\n",
        "            g_optim.zero_grad()\n",
        "            d_pred = D(G(noise, y), y).view(-1)\n",
        "            g_loss = -torch.mean(d_pred)\n",
        "            g_loss.backward()\n",
        "            g_optim.step()\n",
        "            total_g_loss += g_loss.item()\n",
        "\n",
        "    print(f'EPOCH {epoch} | d_loss: {total_d_loss} | g_loss: {total_g_loss}')\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, 10):\n",
        "            gen = G(torch.randn(1, 100, 1, 1).cuda(), torch.tensor([i], device='cuda')).detach().cpu()\n",
        "            img = torch.reshape(gen, (28, 28)).numpy()\n",
        "            img = Image.fromarray(np.uint8(img * 255), 'L')\n",
        "            display(img)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WzqjvjkA0yLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mnist_cgan.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}